{
  "hash": "149b23fa31e51e42652a10be3c5a3be8",
  "result": {
    "markdown": "---\ntitle: \"Attempting drivers of migration\"\nauthor: \"Oluwatosin Orenaike\"\ndate: \"2024-03-13\"\ncategories: [R, Machine Learning, Migration]\nimage: \"image.jpg\"\noutput:\n  html_document:\n    toc: true\n    df_print: paged\n    # keep_md: yes\n    number_sections: true\n  pdf_document:\n    toc: true\n    keep_md: yes\n    number_sections: true\n  word_document:\n    toc: true\n    keep_md: yes\n    number_sections: true\n\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Load Necessary Libraries\n\n\n\n\n\n\nThis is a note for the assessment for the position of a data analyist. The model shows the drivers of international migration at Macro, Meso and Micro.  The argument is that migration is likely to increase if current drivers persist. This assessment will focus on the macro level variables for easy data access. Micro and Meso level are however recommended to take country nuances into consideration. The following variables will be considered in this assessment.\n\n\nData were gathered from the following links and sources, incorporating specific variables relevant to the study:\n\n- **Net Migration**: The difference between the number of people entering and leaving a geographic area over a specific period, serving as a proxy for population movement. [World Bank - Net Migration](https://data.worldbank.org/indicator/SM.POP.NETM?view=chart)\n- **Independent Variables**:\n    - **Economic Factors**:\n        - **Employment Rate**: Reflects the availability of jobs and the health of the economic environment. Regions with higher employment rates attract people due to better job opportunities, acting as a push or pull factor for migrants. This variable is closely linked to **Unemployment** rates, where lower unemployment rates indicate higher employment opportunities. [World Bank - Unemployment](https://data.worldbank.org/indicator/SL.UEM.TOTL.NE.ZS)\n        - **Income Levels**: The average income or economic prosperity in a region, influencing migration as higher income levels often correlate with a higher standard of living. [World Bank - Income Level](https://data.worldbank.org/indicator/NY.GNP.PCAP.CD?view=chart)\n    - **Social and Demographic Factors**:\n        - **Mortality Rate**: While not a direct predictor of migration, it can influence the desirability of a location indirectly through its impact on life expectancy and the quality of healthcare services. [World Bank - Mortality Rate](https://data.worldbank.org/indicator/SH.DYN.MORT?view=chart)\n    - **Population Density**: Provides insight into how densely populated a region is, which can impact migrants' decisions. [World Bank - Population Density](https://data.worldbank.org/indicator/EN.POP.DNST?view=chart)\n    - **Political Instability**: An indicator of the stability of governance in a region, which can significantly affect migration patterns. [World Bank - Worldwide Governance Indicators](https://databank.worldbank.org/source/worldwide-governance-indicators/Series/PV.EST#)\n\nNetMigration ~ EmploymentRate + IncomeLevels + MortalityRate\nNet Migration  = pol_instab + pop_density + under_5_mortality_rate + total_unemployment + govt_expenditure_education + gni_income\n\n**Model Equation**\n\n> * *NetMigration* = $\\beta_0$  + $\\beta_1$ x Political Instability + $\\beta_2$ x Mortiality rate (under 5) + $\\beta_3$x unemployment + $\\beta_4$ x Government expenditure onEducation + $\\beta_5$ x GNI Income* x e\n\n$\\beta_0$ as intercept, $\\beta_1$ , $\\beta_2$ , $\\beta_3$ , $\\beta_4$ , and $\\beta_5$  as coefficients\n\nThe model will try to understand what affects net migration (the difference between the number of people entering and leaving a country) by looking at several factors: political instability, mortality rate for children under 5 years old, unemployment rate, government spending on education, and Gross National Income (GNI) per capital.\n\n## Step 1: Data Gathering\nLoad the variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load first set of dataset  -------------------------\n# Define the base directory\nbase_dir <- \"C:/Users/orenaike/OneDrive/02_JOBS/OT_CV/Jobs_Application/IOM/Interview_Prep/Prep_Grace\"\n\n\n# Define subdirectories\nsub_dirs <- c(\"API_EN.POP.DNST_DS2_en_csv_v2_1512_Pop_Density\",\n              \"API_SH.DYN.MORT_DS2_en_csv_v2_1984_mortality\",\n              \"API_NY.GNP.PCAP.KD_DS2_en_csv_v2_3157_GNI\",\n              \"API_SL.UEM.TOTL.NE.ZS_DS2_en_csv_v2_Unemployment\",\n              \"API_SE.XPD.TOTL.GD.ZS_DS2_en_csv_v2_14_govt_exp\",\n              \"API_SM.POP.NETM_DS2_en_csv_v2_105_Net migration\")\n\n# Initialize an empty list to store data frames\ndf_list <- list()\n\n# Loop through each subdirectory\nfor(dir in sub_dirs) {\n  # Construct the full path to the directory\n  full_dir <- file.path(base_dir, dir)\n  \n  # Find the CSV file that starts with \"API\" in the directory\n  # csv_file <- list.files(full_dir, pattern = \"^API.*//.csv$\", full.names = TRUE)\n  csv_file <- list.files(full_dir, pattern = \"^API.*\\\\.csv$\", full.names = TRUE)\n  \n  # Check if exactly one file is found\n  if(length(csv_file) == 1) {\n    # Read the CSV file from row 5, skip the first 4 rows\n    data <- read.csv(csv_file, skip = 4, stringsAsFactors = FALSE)\n    \n    # Add the data frame to the list\n    df_list[[dir]] <- data\n  } else {\n    cat(\"No file or multiple files found in\", dir, \"/n\")\n  }\n}\n\n# Concatenate all data frames in the list into one\nall_data <- bind_rows(df_list) # The data is currently in wide format. We need to cover to Long for easy analysis \n\n# Check the structure of the concatenated data frame\ndim(all_data) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1596   68\n```\n:::\n\n```{.r .cell-code}\n# load political instability data ----------------\n\npolitical_instab <- read_csv(\"C:/Users/orenaike/OneDrive/02_JOBS/OT_CV/Jobs_Application/IOM/Interview_Prep/Prep_Grace/P_Data_Extract_From_Worldwide_Governance_Indicators/0ac43a1d-ff11-4838-93a9-738e096ed561_Data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 219 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Series Name, Series Code, Country Name, Country Code, 2000 [YR2000...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\npolitical_instab_v1 <- political_instab |>\n  janitor::clean_names() |>\n  dplyr::filter(series_name == \"Political Stability and Absence of Violence/Terrorism: Estimate\")\n\nhead(political_instab_v1) #check the first few\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 15\n  series_name    series_code country_name country_code x2000_yr2000 x2013_yr2013\n  <chr>          <chr>       <chr>        <chr>        <chr>        <chr>       \n1 Political Sta… PV.EST      Afghanistan  AFG          -2.43896889… -2.51934909…\n2 Political Sta… PV.EST      Albania      ALB          -0.53998959… 0.091929785…\n3 Political Sta… PV.EST      Algeria      DZA          -1.43257737… -1.20237147…\n4 Political Sta… PV.EST      American Sa… ASM          ..           0.928985774…\n5 Political Sta… PV.EST      Andorra      AND          1.166981458… 1.283926010…\n6 Political Sta… PV.EST      Angola       AGO          -2.03817391… -0.39123347…\n# ℹ 9 more variables: x2014_yr2014 <chr>, x2015_yr2015 <chr>,\n#   x2016_yr2016 <chr>, x2017_yr2017 <chr>, x2018_yr2018 <chr>,\n#   x2019_yr2019 <chr>, x2020_yr2020 <chr>, x2021_yr2021 <chr>,\n#   x2022_yr2022 <chr>\n```\n:::\n:::\n\n\n# Step 2: Combined all Sourced data into one \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Treating first set of data from world bank--------------------------\nall_data_V1 <- all_data |> \n  janitor::clean_names() |> \n  pivot_longer(\n    cols = starts_with(\"x\"),  # Select columns to gather\n    names_to = \"year\",        # Name of the new column for years\n    names_prefix = \"x\",       # Remove 'x' prefix from year values\n    values_to = \"value\"       # Name of the new column for values\n  ) \n\n## Filter countries of Choice and rename variables\nall_data_V2 <- all_data_V1 |> \n  dplyr::mutate(indicator_name = case_when(\n    indicator_name == \"GNI per capita (constant 2015 US$)\" ~ \"gni_Income\",\n    indicator_name == \"Mortality rate, under-5 (per 1,000 live births)\" ~ \"Under-5_Mortality_Rate\",\n    indicator_name == \"Net migration\" ~ \"Net_Migration\",\n    indicator_name == \"Population density (people per sq. km of land area)\" ~ \"Pop_Density\",\n    indicator_name == \"Unemployment, total (% of total labor force) (national estimate)\" ~ \"Total_Unemployment\",\n    indicator_name == \"Government expenditure on education, total (% of GDP)\" ~ \"Govt_expenditure_education\",\n    TRUE ~ indicator_name\n  )) |>\n  dplyr::select(-indicator_code, -country_code) |> \n  mutate(year = as.numeric(year))\n\n\n### Treating second data source political instability ------------\npolitical_instab_v2 <- political_instab_v1 |>\n  gather(key = \"year\", value = \"value\", -c(series_name, series_code, country_name, country_code)) |> \n  dplyr::mutate(indicator_name = case_when(\n    series_name == \"Political Stability and Absence of Violence/Terrorism: Estimate\" ~ \"pol_instab\",    TRUE ~ series_name\n  )) |>  \n  mutate(year = as.numeric(gsub(\"x(\\\\d+)_yr\\\\d+\", \"\\\\1\", year))) |> \n  mutate(value = as.numeric(ifelse(value == \"..\", NA, value))) |>  \n  dplyr::select(-series_code, -country_code, -series_name)\n\n# combined all data\ncombined_data <- bind_rows(political_instab_v2, all_data_V2)\n\n# filter for country of interest \n\ncombined_data_v1 <- combined_data |> \n  dplyr::filter(country_name == \"Mexico\")\n\n\n# Convert from long to wide format\ncombined_data_v2 <- combined_data_v1 |>\n  pivot_wider(\n    names_from = indicator_name, # Use the indicator name for new column names\n    values_from = value          # The values to populate in the new columns\n  ) |>\n  filter(country_name == \"Mexico\") |>\n  filter(!is.na(year)) |> \n  janitor::clean_names()\n\nhead(combined_data_v2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  country_name  year pol_instab pop_density under_5_mortality_rate gni_income\n  <chr>        <dbl>      <dbl>       <dbl>                  <dbl>      <dbl>\n1 Mexico        2000     -0.200        50.3                   28.3      9457.\n2 Mexico        2013     -0.714        60.3                   17.3      9542.\n3 Mexico        2014     -0.854        61.1                   16.8      9712.\n4 Mexico        2015     -0.802        61.8                   16.2      9846.\n5 Mexico        2016     -0.634        62.5                   15.7      9896.\n6 Mexico        2017     -0.806        63.2                   15.2      9979.\n# ℹ 3 more variables: total_unemployment <dbl>,\n#   govt_expenditure_education <dbl>, net_migration <dbl>\n```\n:::\n\n```{.r .cell-code}\n### Data Overview before Cleaning\nsummary(combined_data_v2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n country_name            year        pol_instab       pop_density   \n Length:63          Min.   :1960   Min.   :-0.8539   Min.   :19.26  \n Class :character   1st Qu.:1976   1st Qu.:-0.8039   1st Qu.:31.10  \n Mode  :character   Median :1991   Median :-0.7142   Median :42.88  \n                    Mean   :1991   Mean   :-0.6999   Mean   :42.91  \n                    3rd Qu.:2006   3rd Qu.:-0.6812   3rd Qu.:54.98  \n                    Max.   :2022   Max.   :-0.2002   Max.   :65.18  \n                                   NA's   :52        NA's   :2      \n under_5_mortality_rate   gni_income    total_unemployment\n Min.   : 13.20         Min.   : 4098   Min.   :1.760     \n 1st Qu.: 22.30         1st Qu.: 6647   1st Qu.:3.275     \n Median : 44.35         Median : 8080   Median :3.733     \n Mean   : 58.09         Mean   : 7839   Mean   :3.936     \n 3rd Qu.: 87.42         3rd Qu.: 9380   3rd Qu.:4.441     \n Max.   :155.20         Max.   :10073   Max.   :7.095     \n NA's   :1                              NA's   :30        \n govt_expenditure_education net_migration    \n Min.   :2.282              Min.   :-641663  \n 1st Qu.:3.681              1st Qu.:-320352  \n Median :4.658              Median :-138534  \n Mean   :4.285              Mean   :-223830  \n 3rd Qu.:4.948              3rd Qu.: -72537  \n Max.   :5.257              Max.   :  33094  \n NA's   :35                                  \n```\n:::\n:::\n\n\nA brief overview of the data reveals the presence of missing values (NAs), which require attention before proceeding with modeling\n\n# Step 3: Data Checks and Cleaning\n\nThis step is crucial for ensuring the quality and reliability of our dataset before moving on to further analysis or modeling. Our approach involves several key actions:\n\nRemove rows with NA values and handle outliers as needed.\n- Handling Missing Values\n- Outlier Detection and Management\n- Check for correlation in variables\n- Encode the categorical if needed\n\n\n### - Handling Missing Values\n\nCheck missing values and justification for mean imputation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initial check for missing values\nmissing_values <- sapply(combined_data_v2, function(x) sum(is.na(x)))\nprint(missing_values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              country_name                       year \n                         0                          0 \n                pol_instab                pop_density \n                        52                          2 \n    under_5_mortality_rate                 gni_income \n                         1                          0 \n        total_unemployment govt_expenditure_education \n                        30                         35 \n             net_migration \n                         0 \n```\n:::\n\n```{.r .cell-code}\n# Function to calculate and print skewness for selected columns with skewness rounded to two decimal places\ncalculate_skewness <- function(data, columns) {\n  for (column in columns) {\n    # Exclude NA values for skewness calculation\n    valid_values <- na.omit(data[[column]])\n    \n    # Calculate skewness\n    skewness <- sum((valid_values - mean(valid_values))^3 / sd(valid_values)^3) / (length(valid_values) - 1)\n    \n    # Print skewness with two decimal places\n    print(sprintf(\"Skewness for %s: %.2f\", column, skewness))\n  }\n}\n\n# Define the columns you want to analyze\ncolumns_to_analyze <- c(\"pol_instab\", \"pop_density\", \"under_5_mortality_rate\", \"gni_income\", \"total_unemployment\", \"govt_expenditure_education\")\n\ncalculate_skewness(combined_data_v2[,-c(1,2)], columns_to_analyze)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Skewness for pol_instab: 1.93\"\n[1] \"Skewness for pop_density: -0.05\"\n[1] \"Skewness for under_5_mortality_rate: 0.77\"\n[1] \"Skewness for gni_income: -0.61\"\n[1] \"Skewness for total_unemployment: 0.68\"\n[1] \"Skewness for govt_expenditure_education: -0.95\"\n```\n:::\n:::\n\n\nChecking missing values and the skewness of the data, median imputation is generally the most appropriate method for our dataset. This decision is based on the robustness of the median to outliers, which are likely present in distributions exhibiting significant skewness, either to the left or right.\n \n### - Mean imputation and re-check\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decision criterion: Focus on data from the last 20 years with <= 24% missing values\n# Missing value imputation for selected columns\ncolumns_to_impute <- c(\"pol_instab\", \"pop_density\", \"under_5_mortality_rate\", \"total_unemployment\", \"govt_expenditure_education\")\n\ncombined_data_v2[columns_to_impute] <- lapply(combined_data_v2[columns_to_impute], function(x) ifelse(is.na(x), median(x, na.rm = TRUE), x))\n\n# Re-check for missing values\nprint(colSums(is.na(combined_data_v2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              country_name                       year \n                         0                          0 \n                pol_instab                pop_density \n                         0                          0 \n    under_5_mortality_rate                 gni_income \n                         0                          0 \n        total_unemployment govt_expenditure_education \n                         0                          0 \n             net_migration \n                         0 \n```\n:::\n\n```{.r .cell-code}\n# Data Overview after mean imputation\n\nsummary(combined_data_v2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n country_name            year        pol_instab       pop_density   \n Length:63          Min.   :1960   Min.   :-0.8539   Min.   :19.26  \n Class :character   1st Qu.:1976   1st Qu.:-0.7142   1st Qu.:31.56  \n Mode  :character   Median :1991   Median :-0.7142   Median :42.88  \n                    Mean   :1991   Mean   :-0.7117   Mean   :42.91  \n                    3rd Qu.:2006   3rd Qu.:-0.7142   3rd Qu.:54.61  \n                    Max.   :2022   Max.   :-0.2002   Max.   :65.18  \n under_5_mortality_rate   gni_income    total_unemployment\n Min.   : 13.20         Min.   : 4098   Min.   :1.760     \n 1st Qu.: 22.50         1st Qu.: 6647   1st Qu.:3.680     \n Median : 44.35         Median : 8080   Median :3.733     \n Mean   : 57.87         Mean   : 7839   Mean   :3.839     \n 3rd Qu.: 86.55         3rd Qu.: 9380   3rd Qu.:3.793     \n Max.   :155.20         Max.   :10073   Max.   :7.095     \n govt_expenditure_education net_migration    \n Min.   :2.282              Min.   :-641663  \n 1st Qu.:4.658              1st Qu.:-320352  \n Median :4.658              Median :-138534  \n Mean   :4.492              Mean   :-223830  \n 3rd Qu.:4.658              3rd Qu.: -72537  \n Max.   :5.257              Max.   :  33094  \n```\n:::\n\n```{.r .cell-code}\n# Check check by years\n# combined_data_v2 |> filter(year == 1960) |> summary()\n```\n:::\n\n\n### - Outlier Detection and Management\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing non-numeric columns for outlier detection\ncombined_data_v3  <-  combined_data_v2[,-c(1,2)] # Removing Frst two columns are country and year\ncombined_data_v4 <- janitor::clean_names(combined_data_v3)\n\n# Generating boxplots for outlier detection\n# Reshape the data to long format\ncombined_data_long <- combined_data_v4 %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Value\")\n\n# Create box plots for all variables\nggplot(combined_data_long, aes(x = Variable, y = Value)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x-axis labels for better readability\n  labs(x = \"Variable\", y = \"Value\", title = \"Box Plot of All Variables\") +\n  facet_wrap(~Variable, scales = \"free_y\") + # Create separate plots for each variable with free y-axis scales \n  scale_y_continuous(labels = label_comma()) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n*Identification*: Outliers are detected using boxplots for each numerical variable, offering a visual examination of data spread and identifying data points that deviate significantly from other observations.\n\n*Decision and Handling:* After identifying notable outliers in key variables like Political Instability, Total Unemployment, and Government Expenditure on Education, the decision to leave these outliers untreated was made based on several thoughtful considerations:\n\n1. Natural Variability: Certain variables, such as Political Instability, are prone to exhibit extreme values in specific contexts due to extraordinary circumstances. These outliers are not just anomalies but represent significant real-world phenomena that merit inclusion in the analysis.\n\n2. Data Integrity and Information Loss: Especially relevant to migration data, outlier removal might lead to the loss of crucial information. The integrity of the original data is paramount, and premature treatment of outliers could risk distorting meaningful patterns, which could be essential for comprehensive analysis.\n\n3. Dataset Considerations: Given the size and scope of the dataset, outright removal of outliers was deemed impractical. It was important to maintain a broad perspective and ensure that any data processing steps did not eliminate valuable insights that could influence the overall findings.\n\n\n### - Correlation Analysis\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute correlation at 2 decimal places\ncorr_matrix = round(cor(combined_data_v4), 2)\n\n# Compute and show the  result\nggcorrplot(corr_matrix, hc.order = TRUE, type = \"lower\",\n          lab = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Visualizing pairwise relationships\npairs(combined_data_v4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n*Initial Correlation Check:* A correlation matrix is generated for all numerical variables to identify any significant relationships between them, this is significant for potential multicollinearity.\n*Findings:* Notable correlations are observed, such as a strong negative correlation between Under-5 Mortality Rate and GNI Income, and a strong positive correlation between Pop Density and GNI Income.\n*Decision:* While correlations are identified, there's no immediate action to remove or adjust variables based solely on correlation..\n\n### Data Trend over the year\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(scales)\n\nlong_data <- pivot_longer(combined_data_v2, \n                          cols = -c(country_name, year), \n                          names_to = \"Indicator\", \n                          values_to = \"Value\")\n\n# Adjusting the script for color differentiation\nggplot(long_data, aes(x = year, y = Value, color = Indicator)) +\n  geom_line() +\n  geom_point() +\n  scale_color_manual(values = c(\"pol_instab\" = \"red\", \"pop_density\" = \"blue\", \"Under-5_Mortality_Rate\" = \"green\", \n                                \"gni_Income\" = \"orange\", \"total_unemployment\" = \"purple\", \"Govt_expenditure_education\" = \"brown\", \n                                \"net_migration\" = \"pink\")) +\n  facet_wrap(~Indicator, scales = \"free_y\") +\n  labs(title = \"Trends of Various Indicators Over Time for Mexico\",\n       x = \"Year\",\n       y = \"Value\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  scale_y_continuous(labels = label_comma()) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# ggsave(\"indicator_trends_colored.png\", width = 12, height = 8)\n```\n:::\n\n\n# Step 4: Model all variable\n\nI choose linear regression because it's straightforward and a solid first step. It shows me how various factors, like population size, impact something else, such as migration. If my initial look at the data suggests clear, straight-line relationships, linear regression is my go-to method. It's also great because I can easily explain it to people who aren't experts, making it very useful for predicting migration patterns.\n\nIn this section, I trained a linear regression model using the `caret` package, with the goal of predicting net migration based on other factors in the dataset. The model's performance is evaluated using cross-validation.\n\n### - Model Training using all variables\n\nNet Migration  = pol_instab + pop_density + under_5_mortality_rate + total_unemployment + govt_expenditure_education + gni_income\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret) # For createDataPartition and postResample\nset.seed(123) # Ensuring reproducibility\n\n\n# Removing non-numeric columns for outlier detection\ncombined_data_v2a  <-  combined_data_v2[,-c(1,2)] # Removing First two columns are country and year \ncombined_data_v5 <- janitor::clean_names(combined_data_v2a)\n\n# Splitting data into training (80%) and testing (20%) sets\nsplitIndex_all <- createDataPartition(combined_data_v5$net_migration, p = .8, list = FALSE)\ntrainData_all <- combined_data_v5[splitIndex_all, ]\ntestData_all <- combined_data_v5[-splitIndex_all, ]\n\nmodel_v1 <- lm(net_migration ~ ., data = trainData_all)\nsummary(model_v1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = net_migration ~ ., data = trainData_all)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-326950  -65575   36473   90490  220227 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)   \n(Intercept)                -2.052e+06  7.086e+05  -2.895  0.00588 **\npol_instab                 -1.273e+05  2.829e+05  -0.450  0.65503   \npop_density                 1.193e+04  3.804e+03   3.136  0.00305 **\nunder_5_mortality_rate      7.228e+03  2.911e+03   2.483  0.01692 * \ngni_income                  6.538e+01  6.353e+01   1.029  0.30904   \ntotal_unemployment          3.019e+04  3.615e+04   0.835  0.40828   \ngovt_expenditure_education  3.937e+04  4.106e+04   0.959  0.34278   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 149700 on 44 degrees of freedom\nMultiple R-squared:  0.3434,\tAdjusted R-squared:  0.2539 \nF-statistic: 3.836 on 6 and 44 DF,  p-value: 0.003669\n```\n:::\n\n```{.r .cell-code}\nactual_responses_all <- testData_all$net_migration\n\n# Correcting the argument name to 'newdata'\npredicted_responses_all <- predict(model_v1, newdata = testData_all)\n\n# Example evaluation metric: RMSE\npostResample(pred = predicted_responses_all, obs = actual_responses_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        RMSE     Rsquared          MAE \n1.370799e+05 6.208449e-01 1.175555e+05 \n```\n:::\n\n```{.r .cell-code}\n# Use postResample to get RMSE and R^2, then calculate MAE separately\nevaluation_metrics_all <- postResample(pred = predicted_responses_all, obs = actual_responses_all)\nlm_rmse_m1 <- evaluation_metrics_all[1]\nlm_mae_m1 <- mean(abs(predicted_responses_all - actual_responses_all))\nlm_r2_m1 <- evaluation_metrics_all[2]\n\n# Outputting the values\ncat(\"LM 1 Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLM 1 Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", lm_rmse_m1, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 137079.9 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", lm_mae_m1, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 117555.5 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R^2:\", lm_r2_m1, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR^2: 0.6208449 \n```\n:::\n:::\n\n\nThe model starts with a base(intercept) level of net migration at negative 2,052,000, which means if all other factors were at zero, the net migration would be a huge negative number. However, this is a theoretical scenario because factors like unemployment rate or GNI per capital can't actually be zero. This also shows that political instability doesn't significantly impact migration in Mexico. A rise in population density increases net migration by 11,930 per unit, suggesting a strong link. Increase in net migration in this context refers to making the net migration number less negative or moving towards a positive value, effectively meaning more people are entering the country than leaving.\n\nHigher child mortality rates also boost net migration, by 7,228 per increase in mortality rate. However, variations in GNI per capita, unemployment rates, and government education spending don't significantly affect migration patterns. \n\n### - Optimizing model 1 using Backward Elimination\n\nThere may be a possibility to optimize model_v1 if insignificant variables is eliminated, sometimes called \"Backward Elimination\" in model building, where you start with all variables and systematically remove the least significant one at each step, based on statistical tests.\n\n#### - model_v1a\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # Ensuring reproducibility\n\n# -------------------\n\n# Removing political instability\ncombined_data_v6 <- combined_data_v5 %>%\n  select(-pol_instab)\n\nset.seed(123) # Ensuring reproducibility\n# Splitting data into training (80%) and testing (20%) sets\nsplitIndex <- createDataPartition(combined_data_v6$net_migration, p = .8, list = FALSE)\ntrainData <- combined_data_v6[splitIndex, ]\ntestData <- combined_data_v6[-splitIndex, ]\n\nmodel_v1a <- lm(net_migration ~ ., data = trainData)\nsummary(model_v1a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = net_migration ~ ., data = trainData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-329738  -66926   42885   91552  220684 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)   \n(Intercept)                -1.967e+06  6.771e+05  -2.905  0.00567 **\npop_density                 1.202e+04  3.765e+03   3.194  0.00257 **\nunder_5_mortality_rate      7.182e+03  2.883e+03   2.491  0.01650 * \ngni_income                  6.322e+01  6.278e+01   1.007  0.31935   \ntotal_unemployment          3.324e+04  3.519e+04   0.945  0.34994   \ngovt_expenditure_education  4.145e+04  4.043e+04   1.025  0.31069   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 148400 on 45 degrees of freedom\nMultiple R-squared:  0.3404,\tAdjusted R-squared:  0.2671 \nF-statistic: 4.645 on 5 and 45 DF,  p-value: 0.001675\n```\n:::\n\n```{.r .cell-code}\nactual_responses <- testData$net_migration\n\n# Correcting the argument name to 'newdata'\npredicted_responses <- predict(model_v1a, newdata = testData)\n\n# Example evaluation metric: RMSE\npostResample(pred = predicted_responses, obs = actual_responses)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        RMSE     Rsquared          MAE \n1.374380e+05 6.169030e-01 1.181483e+05 \n```\n:::\n\n```{.r .cell-code}\n# Use postResample to get RMSE and R^2, then calculate MAE separately\nevaluation_metrics <- postResample(pred = predicted_responses, obs = actual_responses)\nlm_rmse_mv1a <- evaluation_metrics[1] \nlm_mae_mv1a <- mean(abs(predicted_responses - actual_responses))\nlm_r2_mv1a <- evaluation_metrics[2] # R^2 is the second element\n\n# Outputting the values\ncat(\"LM 2 Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLM 2 Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", lm_rmse_mv1a, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 137438 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", lm_mae_mv1a, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 118148.3 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R^2:\", lm_r2_mv1a, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR^2: 0.616903 \n```\n:::\n:::\n\n\n#### - model_v1b\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing political instability\ncombined_data_v6 <- combined_data_v5 %>%\n  select(-pol_instab, -total_unemployment)\n\nset.seed(123) # Ensuring reproducibility\n# Splitting data into training (80%) and testing (20%) sets\nsplitIndex <- createDataPartition(combined_data_v6$net_migration, p = .8, list = FALSE)\ntrainData <- combined_data_v6[splitIndex, ]\ntestData <- combined_data_v6[-splitIndex, ]\n\nmodel_v1b <- lm(net_migration ~ ., data = trainData)\nsummary(model_v1b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = net_migration ~ ., data = trainData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-345496  -84985   55726   88515  211264 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)   \n(Intercept)                -1.585e+06  5.421e+05  -2.923  0.00536 **\npop_density                 1.236e+04  3.744e+03   3.301  0.00187 **\nunder_5_mortality_rate      5.809e+03  2.487e+03   2.335  0.02393 * \ngni_income                  3.087e+01  5.256e+01   0.587  0.55985   \ngovt_expenditure_education  5.622e+04  3.724e+04   1.509  0.13805   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 148200 on 46 degrees of freedom\nMultiple R-squared:  0.3273,\tAdjusted R-squared:  0.2688 \nF-statistic: 5.596 on 4 and 46 DF,  p-value: 0.000934\n```\n:::\n\n```{.r .cell-code}\nactual_responses <- testData$net_migration\n\n# Correcting the argument name to 'newdata'\npredicted_responses <- predict(model_v1b, newdata = testData)\n\n# Example evaluation metric: RMSE\npostResample(pred = predicted_responses, obs = actual_responses)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        RMSE     Rsquared          MAE \n1.584531e+05 4.064123e-01 1.341404e+05 \n```\n:::\n\n```{.r .cell-code}\n# Use postResample to get RMSE and R^2, then calculate MAE separately\nevaluation_metrics <- postResample(pred = predicted_responses, obs = actual_responses)\nlm_rmse_mv1b <- evaluation_metrics[1] \nlm_mae_mv1b <- mean(abs(predicted_responses - actual_responses))\nlm_r2_mv1b <- evaluation_metrics[2] # R^2 is the second element\n\n# Outputting the values\ncat(\"LM 2 Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLM 2 Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", lm_rmse_mv1b, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 158453.1 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", lm_mae_mv1b, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 134140.4 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R^2:\", lm_r2_mv1b, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR^2: 0.4064123 \n```\n:::\n:::\n\n#### - model_v1c\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing political instability\ncombined_data_v6 <- combined_data_v5 %>%\n  select(-pol_instab, -total_unemployment, -gni_income)\n\nset.seed(123) # Ensuring reproducibility\n# Splitting data into training (80%) and testing (20%) sets\nsplitIndex <- createDataPartition(combined_data_v6$net_migration, p = .8, list = FALSE)\ntrainData <- combined_data_v6[splitIndex, ]\ntestData <- combined_data_v6[-splitIndex, ]\n\nmodel_v1c <- lm(net_migration ~ ., data = trainData)\nsummary(model_v1c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = net_migration ~ ., data = trainData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-367616  -77530   52164   85696  223190 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                -1298687     236653  -5.488 1.59e-06 ***\npop_density                   12430       3716   3.346 0.001621 ** \nunder_5_mortality_rate         4544       1235   3.679 0.000601 ***\ngovt_expenditure_education    62172      35587   1.747 0.087159 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 147200 on 47 degrees of freedom\nMultiple R-squared:  0.3223,\tAdjusted R-squared:  0.279 \nF-statistic:  7.45 on 3 and 47 DF,  p-value: 0.0003517\n```\n:::\n\n```{.r .cell-code}\nactual_responses <- testData$net_migration\n\n# Correcting the argument name to 'newdata'\npredicted_responses <- predict(model_v1c, newdata = testData)\n\n# Example evaluation metric: RMSE\npostResample(pred = predicted_responses, obs = actual_responses)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        RMSE     Rsquared          MAE \n1.650779e+05 3.335848e-01 1.373180e+05 \n```\n:::\n\n```{.r .cell-code}\n# Use postResample to get RMSE and R^2, then calculate MAE separately\nevaluation_metrics <- postResample(pred = predicted_responses, obs = actual_responses)\nlm_rmse_mv1c <- evaluation_metrics[1] \nlm_mae_mv1c <- mean(abs(predicted_responses - actual_responses))\nlm_r2_mv1c <- evaluation_metrics[2] # R^2 is the second element\n\n# Outputting the values\ncat(\"LM 2 Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLM 2 Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", lm_rmse_mv1c, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 165077.9 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", lm_mae_mv1c, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 137318 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R^2:\", lm_r2_mv1c, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR^2: 0.3335848 \n```\n:::\n:::\n\n#### - model_v1d\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing political instability\ncombined_data_v6 <- combined_data_v5 %>%\n  select(-pol_instab, -total_unemployment,-gni_income, -govt_expenditure_education )\n\nset.seed(123) # Ensuring reproducibility\n# Splitting data into training (80%) and testing (20%) sets\nsplitIndex <- createDataPartition(combined_data_v6$net_migration, p = .8, list = FALSE)\ntrainData <- combined_data_v6[splitIndex, ]\ntestData <- combined_data_v6[-splitIndex, ]\n\nmodel_v1d <- lm(net_migration ~ ., data = trainData)\nsummary(model_v1d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = net_migration ~ ., data = trainData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-371085  -74282   34622   89212  242203 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -1137628     222569  -5.111 5.51e-06 ***\npop_density               14326       3629   3.948 0.000257 ***\nunder_5_mortality_rate     5181       1205   4.300 8.32e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 150300 on 48 degrees of freedom\nMultiple R-squared:  0.2783,\tAdjusted R-squared:  0.2482 \nF-statistic: 9.254 on 2 and 48 DF,  p-value: 0.000399\n```\n:::\n\n```{.r .cell-code}\nactual_responses <- testData$net_migration\n\n# Correcting the argument name to 'newdata'\npredicted_responses <- predict(model_v1d, newdata = testData)\n\n# Example evaluation metric: RMSE\npostResample(pred = predicted_responses, obs = actual_responses)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        RMSE     Rsquared          MAE \n1.591383e+05 5.786589e-01 1.280952e+05 \n```\n:::\n\n```{.r .cell-code}\n# Use postResample to get RMSE and R^2, then calculate MAE separately\nevaluation_metrics <- postResample(pred = predicted_responses, obs = actual_responses)\nlm_rmse_mv1d <- evaluation_metrics[1] \nlm_mae_mv1d <- mean(abs(predicted_responses - actual_responses))\nlm_r2_mv1d <- evaluation_metrics[2] # R^2 is the second element\n\n# Outputting the values\ncat(\"LM 2 Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLM 2 Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", lm_rmse_mv1d, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 159138.3 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", lm_mae_mv1d, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 128095.2 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R^2:\", lm_r2_mv1d, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR^2: 0.5786589 \n```\n:::\n:::\n\n\nRemoving factors generally leads to a decrease in R-squared, suggesting a decline in the model's explanatory power. Though However, removing GNI income and government expenditure on education in model_v1d seems to have resulted in a significant improvement in R-squared. comprehensive model (v1) had a good balance of explanatory power and prediction accuracy, with an R² of approximately 0.6208.\n\n\n# Step 5: Linearity assumptions checks\n\nL: Linearity of Variable outcomes\nI: Independence of residuals\nN: Normality of residuals\nE: Equality of variance (homoscedasticity)\n\n\n### - LM Diagnostic Plots\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=10)\npar(mfrow=c(2,2))\nplot(model_v1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nDiagnostic plots reveal potential non-linearity, heteroscedasticity, deviations from normality in residuals, and influential observations.\n\nThe diagnostic plots for the linear regression model suggest several issues regarding the linearity assumptions:\n\n1. **Residuals vs Fitted Plot**: The residuals do not appear to be randomly dispersed around the horizontal line at zero. Instead, they show a pattern, which is not ideal.\n\n2. **Q-Q Plot of Residuals**: The Q-Q plot deviates from the straight line, particularly at the ends, suggesting the residuals do not follow a normal distribution perfectly, which could affect the model's reliability.\n\n3. **Scale-Location Plot**: This plot, also known as the Spread-Location plot, shows a pattern (funnel shape), which implies heteroscedasticity — the variance of the residuals is not constant across all levels of fitted values.\n\n4. **Residuals vs Leverage Plot**: This plot helps us to find observations that have a more pronounced effect on the calculation of the regression coefficients. The presence of points in the top right and bottom right corners could indicate influential outliers.\n\n\n\n### - Multicollinearity Check (VIF)\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n# Calculating VIF\nvif_results <- vif(model_v1)\nprint(vif_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                pol_instab                pop_density \n                  1.119655                   6.180243 \n    under_5_mortality_rate                 gni_income \n                 32.828127                  28.457074 \n        total_unemployment govt_expenditure_education \n                  1.627980                   1.413640 \n```\n:::\n:::\n\nThe Variance Inflation Factor (VIF) results reveal high values for 'under_5_mortality_rate' and 'gni_income', which suggest significant multicollinearity; these variables are not independent of each other and could be inflating the variance of the coefficient estimates.\n\n### - Independence of Residuals\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\ndurbinWatsonTest(model_v1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n lag Autocorrelation D-W Statistic p-value\n   1       0.6407516     0.7097702       0\n Alternative hypothesis: rho != 0\n```\n:::\n\n```{.r .cell-code}\n# Aim: To check that the residuals are independent, an assumption that autocorrelation violates.\nlmtest::dwtest(model_v1) # Durbin-Watson test for autocorrelation # Aim: DW statistic close to 2 suggests independence; <1 or >3 indicates potential autocorrelation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tDurbin-Watson test\n\ndata:  model_v1\nDW = 0.70977, p-value = 0.000000003988\nalternative hypothesis: true autocorrelation is greater than 0\n```\n:::\n:::\n\n\nThe Durbin-Watson test result (DW = 0.70977) indicates a strong positive autocorrelation in the residuals, as the value is much less than 2. This is further supported by the very low p-value, implying that the independence of residuals assumption is violated.\n\n### - Independence of Observations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###  Checking for Independence of Observations ------------\n# Durbin-Watson test\ndwtest(model_v1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tDurbin-Watson test\n\ndata:  model_v1\nDW = 0.70977, p-value = 0.000000003988\nalternative hypothesis: true autocorrelation is greater than 0\n```\n:::\n:::\n\n### - Check outlier influence \n\n::: {.cell}\n\n```{.r .cell-code}\n# Outliers and Influential Data Points -----\n# Aim: To identify and investigate outliers and influential observations that could unduly affect the model.\nolsrr::ols_plot_dfbetas(model_v1) #Aim: Values > 1 suggest influential observations\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n\n```{.r .cell-code}\nolsrr::ols_test_outlier(model_v1) # Statistical test for outliers\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   studentized_residual unadjusted_p_val bonferroni_p_val\n11            -4.570857    0.00004071165      0.002076294\n```\n:::\n\n```{.r .cell-code}\nplot(model_v1, which = 4) # Cook's distance for influential outliers\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-3.png){width=672}\n:::\n:::\n\n\n\nIn conclusion, the linear regression model does not fully meet the assumptions of linearity, homoscedasticity, independence of residuals, and normality of errors. Hence the need to consider a different modeling approaches like GAM, which can handle these complexities more effectively.\n\n# Step 6:  Generalized Additive Model (GAM)\nThe next attempt was to use Generalized Additive Model (GAM) due to the shortcoming os LN. GAM is a flexible approach to modeling relationships between a dependent variable and one or more independent variables. It is an extension of General Linear Models (GLM) where the linear predictor involves a sum of smooth functions of predictors rather than just the predictors themselves.This allows GAMs to handle non-linear relationships in a straightforward manner, providing a powerful tool for exploring complex data structures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean names first\ncombined_data_v3 <- combined_data_v2 |> clean_names()\n\nset.seed(123) # Ensure reproducibility\ntraining_index <- createDataPartition(combined_data_v3$net_migration, p = 0.91, list = FALSE) # 0.91 was used because the models need for higher observation\ntraining_data <- combined_data_v3[training_index, ]\ntesting_data <- combined_data_v3[-training_index, ]\n\n# Then, ensure 'year' is treated as numeric\ntraining_data$year <- as.numeric(as.character(training_data$year))\ntesting_data$year <- as.numeric(as.character(testing_data$year)) # Do the same for testing data\n\n# Fit a GAM model on the training data\ngam_model_t <- gam(net_migration ~ s(pol_instab) + s(under_5_mortality_rate) + s(gni_income) + \n                 s(total_unemployment) + s(year, bs=\"cr\"), data=training_data)\nsummary(gam_model_t)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nnet_migration ~ s(pol_instab) + s(under_5_mortality_rate) + s(gni_income) + \n    s(total_unemployment) + s(year, bs = \"cr\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -222991       6746  -33.05   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                            edf Ref.df     F  p-value    \ns(pol_instab)             1.000  1.000 0.798 0.376753    \ns(under_5_mortality_rate) 8.247  8.430 5.229 0.000230 ***\ns(gni_income)             2.475  3.255 2.032 0.143593    \ns(total_unemployment)     1.000  1.000 2.175 0.147772    \ns(year)                   3.534  3.916 7.537 0.000257 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.912   Deviance explained = 93.7%\nGCV = 3.7953e+09  Scale est. = 2.6853e+09  n = 59\n```\n:::\n\n```{.r .cell-code}\n# Make predictions on the testing data -----------\ngam_predictions <- predict(gam_model_t, testing_data)\n\n# Now define 'actual' as the true net_migration values from the testing_data\nactual <- testing_data$net_migration\nresiduals <- actual - gam_predictions # Calculate residuals\nSS_res <- sum(residuals^2) # Calculate SS_res (sum of squares of residuals)\n# Calculate SS_tot (total sum of squares)\nmean_actual <- mean(actual)\nSS_tot <- sum((actual - mean_actual)^2)\n# Calculate R^2\nR2 <- 1 - (SS_res / SS_tot)\n\n# Calculate MAE and RMSE using actual and predicted values\ngam_mae <- mae(actual, gam_predictions)\ngam_rmse <- rmse(actual, gam_predictions)\n\n# Print the metrics\ncat(\"GAM Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAM Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", gam_mae, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 93105.75 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", gam_rmse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 115846.4 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R-squared:\", R2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR-squared: 0.7237168 \n```\n:::\n:::\n\n\nGAM model analysis indicates that child mortality rate and time (year) are significant predictors of net migration, while political instability, income levels, and unemployment are not significant. The model explains a large portion of the variance in net migration (93.7% deviance explained) and performs well on test data with an adjusted R-squared value of 0.72, suggesting good predictive power. The model's predictions are relatively accurate, with a Mean Absolute Error (MAE) of approximately 93,106 and a Root Mean Square Error (RMSE) of approximately 115,846, which are the average deviations from the actual values. There will be a need to also carry out a diagnostics test next.\n\n\n### - GAM Diagnostic Plots\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=10)\npar(mfrow=c(2,3))\nplot(gam_model_t)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nThe partial regression plots suggest that political instability and unemployment have little effect on net migration, whereas under-5 mortality rate, GNI income, and possibly time show nonlinear relationships with net migration. The model's complexity and non-linear terms indicate intricate dynamics in how these predictors influence net migration trends.\n\n\n# Step 7: Compare model LM and GAM 1\n\nI compared the linear model (LM) performance with the Generalized Additive Model (GAM), performance based on three statistical measures:\n\n- RMSE: Reflects the average error in predictions. Lower values indicate higher accuracy.\n- R-squared: Shows how much of the migration variance is explained by the model. Higher values mean a better fit.\n- MAE: Represents the average absolute error in predictions.\n\n### - Comparison of Model Performance: LM(80% Training Data) and GAM (91% Training Data)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(caret) # for prediction and possibly for RMSE and MAE if used directly\nlibrary(mgcv) # for GAM models\n# Assuming other necessary libraries (like janitor) are loaded\n\n# Assuming dataset is loaded, pre-processed, and models (lm and gam) are trained\n\n# Calculate metrics for Linear Model\nlm_predicted <- predict(model_v1, newdata = testData_all)\nlm_mae <- mean(abs(lm_predicted - testData_all$net_migration))\nlm_rmse <- sqrt(mean((lm_predicted - testData_all$net_migration)^2))\nlm_r2 <- summary(model_v1)$r.squared\n\n# Automatically calculate metrics for GAM Model\ngam_predictions <- predict(gam_model_t, newdata = testing_data)\ngam_mae <- mean(abs(gam_predictions - testing_data$net_migration))\ngam_rmse <- sqrt(mean((gam_predictions - testing_data$net_migration)^2))\n\n# Calculating R2 for GAM using the residuals and total sum of squares\ngam_residuals <- testing_data$net_migration - gam_predictions\nSS_res_gam <- sum(gam_residuals^2)\nSS_tot_gam <- sum((testing_data$net_migration - mean(testing_data$net_migration))^2)\ngam_r2 <- 1 - (SS_res_gam / SS_tot_gam)\n\n# Combine metrics into a data frame for comparison\ncomparison_table_v1 <- data.frame(\n  Model = c(\"LM_v1\", \"GAM\"),\n  MAE = c(lm_mae, gam_mae),\n  RMSE = c(lm_rmse, gam_rmse),\n  R_squared = c(lm_r2, gam_r2)\n)\n\n\n## Comapare model_v1 and Model GAM ----------------------------------\n\n# Print the comparison table\nprint(comparison_table_v1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Model       MAE     RMSE R_squared\n1 LM_v1 117555.45 137079.9 0.3434263\n2   GAM  93105.75 115846.4 0.7237168\n```\n:::\n\n```{.r .cell-code}\n# Melting the data frame to use with ggplot\ncomparison_table_long <- comparison_table_v1 %>%\n  pivot_longer(cols = c(MAE, RMSE, R_squared), names_to = \"Metric\", values_to = \"Value\")\n\n# Plotting with faceting\nggplot(comparison_table_long, aes(x = Model, y = Value, fill = Model)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  theme_minimal() +\n  labs(title = \"Comparison of Model Performance Across Metrics Model_v1 and GAM\",\n       x = \"\",\n       y = \"Value\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  facet_wrap(~Metric, scales = \"free_y\", nrow = 1) +\n  scale_y_continuous(labels = label_comma()) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 1\n $ legend.position: chr \"none\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n```\n:::\n:::\n\n\n### - Model_v3- Change Sample size for LM model_v1 \n\nIt may be fair to attempt and compare using same sampple data i.e 91%\nSince the GAM model's approach to partitioning more data for training (91%) vs. the LM's 80% might have contributed to its better performance by allowing the model to learn more nuanced patterns in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret) # For createDataPartition and postResample\nset.seed(123) # Ensuring reproducibility\n\n\n# Removing non-numeric columns for outlier detection\ncombined_data_v2a  <-  combined_data_v2[,-c(1,2)] # Removing First two columns are country and year \ncombined_data_v5 <- janitor::clean_names(combined_data_v2a)\n\n# Splitting data into training (80%) and testing (20%) sets\nsplitIndex_all <- createDataPartition(combined_data_v5$net_migration, p = .91, list = FALSE)\ntrainData_all <- combined_data_v5[splitIndex_all, ]\ntestData_all <- combined_data_v5[-splitIndex_all, ]\n\nmodel_v3 <- lm(net_migration ~ ., data = trainData_all)\nsummary(model_v3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = net_migration ~ ., data = trainData_all)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-347844  -55003   42524   89701  228756 \n\nCoefficients:\n                              Estimate  Std. Error t value Pr(>|t|)    \n(Intercept)                -2626877.98   653807.41  -4.018 0.000190 ***\npol_instab                  -119642.57   266979.21  -0.448 0.655918    \npop_density                   11442.52     3696.86   3.095 0.003164 ** \nunder_5_mortality_rate         9738.22     2707.12   3.597 0.000716 ***\ngni_income                      123.37       61.21   2.015 0.049042 *  \ntotal_unemployment            58252.22    32883.38   1.771 0.082341 .  \ngovt_expenditure_education    15857.21    35950.14   0.441 0.660977    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 146100 on 52 degrees of freedom\nMultiple R-squared:  0.3745,\tAdjusted R-squared:  0.3024 \nF-statistic:  5.19 on 6 and 52 DF,  p-value: 0.0003013\n```\n:::\n\n```{.r .cell-code}\nactual_responses_all <- testData_all$net_migration\n\n# Correcting the argument name to 'newdata'\npredicted_responses_all <- predict(model_v3, newdata = testData_all)\n\n# Example evaluation metric: RMSE\npostResample(pred = predicted_responses_all, obs = actual_responses_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          RMSE       Rsquared            MAE \n124442.8394807      0.7363499 109559.1876224 \n```\n:::\n\n```{.r .cell-code}\n# Use postResample to get RMSE and R^2, then calculate MAE separately\nevaluation_metrics_all <- postResample(pred = predicted_responses_all, obs = actual_responses_all)\nlm_rmse_mv3 <- evaluation_metrics_all[1]\nlm_mae_mv3 <- mean(abs(predicted_responses_all - actual_responses_all))\nlm_r2_mv3 <- evaluation_metrics_all[2]\n\n# Outputting the values\ncat(\"LM 1 Model Performance on Test Data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLM 1 Model Performance on Test Data:\n```\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", lm_rmse_mv3, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE: 124442.8 \n```\n:::\n\n```{.r .cell-code}\ncat(\"RMSE:\", lm_mae_mv3, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 109559.2 \n```\n:::\n\n```{.r .cell-code}\ncat(\"R^2:\", lm_r2_mv3, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR^2: 0.7363499 \n```\n:::\n:::\n\n\n### - Comparison of Model Performance: model_v3 LM(91% Training Data) and GAM (91% Training Data) - Equal Sample\n\nThis is a comparison of LM and GAM Model on equal sampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(caret) # for prediction and possibly for RMSE and MAE if used directly\nlibrary(mgcv) # for GAM models\n# Assuming other necessary libraries (like janitor) are loaded\n\n# Assuming dataset is loaded, pre-processed, and models (lm and gam) are trained\n\n# Calculate metrics for Linear Model\nlm_predicted <- predict(model_v3, newdata = testData_all)\nlm_mae <- mean(abs(lm_predicted - testData_all$net_migration))\nlm_rmse <- sqrt(mean((lm_predicted - testData_all$net_migration)^2))\nlm_r2 <- summary(model_v3)$r.squared\n\n# Automatically calculate metrics for GAM Model\ngam_predictions_v3 <- predict(gam_model_t, newdata = testing_data)\ngam_mae_v3 <- mean(abs(gam_predictions_v3 - testing_data$net_migration))\ngam_rmse_v3 <- sqrt(mean((gam_predictions_v3 - testing_data$net_migration)^2))\n\n# Calculating R2 for GAM using the residuals and total sum of squares\ngam_residuals_v3 <- testing_data$net_migration - gam_predictions_v3\nSS_res_gam_v3 <- sum(gam_residuals_v3^2)\nSS_tot_gam_v3 <- sum((testing_data$net_migration - mean(testing_data$net_migration))^2)\ngam_r2_v3 <- 1 - (SS_res_gam_v3 / SS_tot_gam_v3)\n\n# Combine metrics into a data frame for comparison\ncomparison_table_v2 <- data.frame(\n  Model = c(\"LM_V3\", \"GAM\"),\n  MAE = c(lm_mae, gam_mae_v3),\n  RMSE = c(lm_rmse, gam_rmse_v3),\n  R_squared = c(lm_r2, gam_r2_v3)\n)\n\n# Print the comparison table\nprint(comparison_table_v2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Model       MAE     RMSE R_squared\n1 LM_V3 109559.19 124442.8 0.3745465\n2   GAM  93105.75 115846.4 0.7237168\n```\n:::\n\n```{.r .cell-code}\n## Comapare model_v3 and Model GAM ----------------------------------\n\n\n# Melting the data frame to use with ggplot\ncomparison_table_long <- comparison_table_v2 %>%\n  pivot_longer(cols = c(MAE, RMSE, R_squared), names_to = \"Metric\", values_to = \"Value\")\n\n# Plotting with faceting\nggplot(comparison_table_long, aes(x = Model, y = Value, fill = Model)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  theme_minimal() +\n  labs(title = \"Comparison of Model Performance Across Metrics Model_v3 and GAM\",\n       x = \"\",\n       y = \"Value\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  facet_wrap(~Metric, scales = \"free_y\", nrow = 1) +\n  scale_y_continuous(labels = label_comma()) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 1\n $ legend.position: chr \"none\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n```\n:::\n:::\n\n\nEven with the adjustment of the samples for LN. the R Square is still compared to GAM\n\n# Step 8: Conclusion\n\nI attempt to understand the factors influencing net migration, including political instability, population density, mortality rates, unemployment, education expenditure, and income levels in Mexico. For this purpose, I use two statistical models: Linear Regression (LM) and Generalized Additive Models (GAM).\n\n**Key Findings:**\n\n- In the **Linear Regression (LM)** analysis, I found that population density and under-5 mortality rates significantly influence net migration. A higher population density correlates with increased net migration, suggesting that denser areas might be more appealing to migrants. Interestingly, the under-5 mortality rate, a surprising predictor, also showed a positive association, hinting at complex underlying socio-economic factors. Specifically, for every unit increase in population density, net migration increases by approximately 11,440 people. Furthermore, an increase in the under-5 mortality rate by one unit is associated with an increase in net migration by about 7,228 people. However the linear regression model does not fully meet the assumptions of linearity, homoscedasticity, independence of residuals, and normality of errors hence the need for GAM.\n\n- The **Generalized Additive Model (GAM)** highlighted non-linear relationships between the predictors and net migration, especially emphasizing the role of time and under-5 mortality rates. This indicates that the impact of these factors on migration is more intricate than initially assumed. The GAM model explained roughly 93.7% of the variance in net migration, demonstrating its strong predictive capability.\n\n**Model Performance:**\n\n- The GAM model achieved an R-squared value of 0.72, showing that it could explain 72% of the variation in net migration. This represents a significant improvement over the linear regression model.\n\n**Conclusion:**\nMy analysis highlights the complexity of migration and the significance of considering a range of socio-economic and demographic factors in understanding in mexico. While LM provided initial insights, the flexibility of GAM in modeling non-linear relationships offered a deeper understanding of the dynamics involved. This analysis can guide policymakers and researchers in recognizing the multifaceted nature of migration, emphasizing the need for nuanced approaches in both research and policy-making.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}