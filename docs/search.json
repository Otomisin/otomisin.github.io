[
  {
    "objectID": "Maps.html#static-maps",
    "href": "Maps.html#static-maps",
    "title": "MAPS",
    "section": "1.0 STATIC MAPS",
    "text": "1.0 STATIC MAPS\n\nArctic Sea Ice decline\n\n\n\n\nReport Maps\n Link to Report publication\n\n\n\nPapau New Guinea\n\n\n\nContext: Administrative Map  Tools: ArcGIS Pro Date: January 2023\n\n\n\n\n\nSouth Sudan\n\n\n\nContext: Administrative Map\n\n\n\n\n\n\n## 2.0 INTERACTIVE MAPS\n\n\n\nArGIS Online\nA Bangladesh map showing Spatial flood risk assessment in the Ganges-Brahmaputra-Meghna delta in Bangladesh\nFlood Risk App\nThis map shows Spatial flood risk assessment in the Ganges-Brahmaputra-Meghna delta in Bangladesh. This assessment calculated flood risk using the equation; FLOOD RISK = FLOOD HAZARD x FLOOD EXPOSURE x VULNERABILITIES.(Tutorial Purpose)\n\n\nThe index score used ranges from 0-1. with 0 being least at risk and 1 being most at risk of floods\n\nSomalia River Basin The River Basins in Somalia\n\niFrames are not supported on this page.\n\n\n\nWest African cities (in Progress)\nA Leaflet map to show the location of cities and their nearest cities, boarders and populations\n\n# Load the necessary packages\nlibrary(leaflet)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Create a data frame with the capital cities and their coordinates\nwest_africa &lt;- data.frame(\n  country = c(\"Nigeria\", \"Ghana\", \"Sierra Leone\", \"Liberia\", \"Cote d'Ivoire\", \"Burkina Faso\", \"Mali\", \"Senegal\", \"Guinea-Bissau\", \"Guinea\", \"Gambia\", \"Togo\", \"Benin\"),\n  capital_city = c(\"Abuja\", \"Accra\", \"Freetown\", \"Monrovia\", \"Yamoussoukro\", \"Ouagadougou\", \"Bamako\", \"Dakar\", \"Bissau\", \"Conakry\", \"Banjul\", \"Lome\", \"Porto-Novo\"),\n  latitude = c(9.0765, 5.6037, 8.4840, 6.3106, 6.8206, 12.3714, 12.6392, 14.7167, 11.8630, 9.5357, 13.4531, 6.1319, 6.4968),\n  longitude = c(7.3986, -0.1870, -13.2299, -10.8047, -5.2764, -1.5330, -8.0029, -17.4677, -15.5976, -13.6788, -16.5790, 1.2221, 2.6059)\n)\n\n# Create the map using Leaflet\nleaflet(west_africa, options = leafletOptions(width = \"800px\")) %&gt;%\n  addTiles() %&gt;%\n  addMarkers(\n    ~longitude,\n    ~latitude,\n    popup = ~paste(country, \"&lt;br&gt;\", capital_city, sep = \"\")\n  )"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Quarto Testing",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n\n\n\nThis is the content I am working with now\n\n\nI want to also stlye this one as well\n\n\n\nHere is a warning.\n\nMore content.\n\n\nHere is a warning."
  },
  {
    "objectID": "talks.html#quarto",
    "href": "talks.html#quarto",
    "title": "Quarto Testing",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n\n\n\nThis is the content I am working with now\n\n\nI want to also stlye this one as well\n\n\n\nHere is a warning.\n\nMore content.\n\n\nHere is a warning."
  },
  {
    "objectID": "talks.html#another-one",
    "href": "talks.html#another-one",
    "title": "Quarto Testing",
    "section": "Another one",
    "text": "Another one\n\n&lt;h1 style=\"text-align: center; font-size: 3em;\"&gt;Portfolio&lt;/h1&gt;\n&lt;p style=\"font-size: 1.2em;\"&gt;\n    Whether you’re looking for &lt;span style=\"background-color: #1D3518;\"&gt;crystal clear communication&lt;/span&gt; of data insights, an \n    &lt;span style=\"background-color: #ccffcc;\"&gt;artistic response&lt;/span&gt; to the data, or something between the two, I enjoy putting together \n    stand-out visuals which will keep the conversation going. From academic graphs to artistic commemorations, \n    via interactive visualisations, generative art and animations with a sense of humour, my portfolio features \n    a range of different styles, all coded straight from the data. \n    &lt;br&gt;&lt;br&gt;\n    Click and scroll for full screen view. I have also included here some packages and Shiny Apps I have built. \n    &lt;strong&gt;Happy browsing!&lt;/strong&gt;\n&lt;/p&gt;"
  },
  {
    "objectID": "talks.html#imagies",
    "href": "talks.html#imagies",
    "title": "Quarto Testing",
    "section": "Imagies",
    "text": "Imagies\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\nAn Elephant\n\n\nThis is illustrated well by Figure 1."
  },
  {
    "objectID": "talks.html#tables",
    "href": "talks.html#tables",
    "title": "Quarto Testing",
    "section": "Tables",
    "text": "Tables\n\n\n\nDefault\nLeft\nRight\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\nFruit prices\n\n\n\n\n\n\nfruit\nprice\n\n\n\n\napple\n2.05\n\n\npear\n1.37\n\n\norange\n3.09"
  },
  {
    "objectID": "talks.html#embedding-from-other-documents",
    "href": "talks.html#embedding-from-other-documents",
    "title": "Quarto Testing",
    "section": "Embedding from Other Documents",
    "text": "Embedding from Other Documents\nHere is the embebded document"
  },
  {
    "objectID": "talks.html#sources-of-inspiration",
    "href": "talks.html#sources-of-inspiration",
    "title": "Quarto Testing",
    "section": "Sources of inspiration",
    "text": "Sources of inspiration\n\n\n#TidyTuesday on Twitter - get involved!\nDataviz / design books\nKids books (palettes!)\nDatajournalists (John Burn-Murdoch - @jburnmurdoch)\nArtists (local art gallery / Twitter accounts e.g. @womensart1)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Attempting drivers of migration",
    "section": "",
    "text": "This is a note for the assessment for the position of a data analyist. The model shows the drivers of international migration at Macro, Meso and Micro. The argument is that migration is likely to increase if current drivers persist. This assessment will focus on the macro level variables for easy data access. Micro and Meso level are however recommended to take country nuances into consideration. The following variables will be considered in this assessment.\nData were gathered from the following links and sources, incorporating specific variables relevant to the study:\n\nNet Migration: The difference between the number of people entering and leaving a geographic area over a specific period, serving as a proxy for population movement. World Bank - Net Migration\nIndependent Variables:\n\nEconomic Factors:\n\nEmployment Rate: Reflects the availability of jobs and the health of the economic environment. Regions with higher employment rates attract people due to better job opportunities, acting as a push or pull factor for migrants. This variable is closely linked to Unemployment rates, where lower unemployment rates indicate higher employment opportunities. World Bank - Unemployment\nIncome Levels: The average income or economic prosperity in a region, influencing migration as higher income levels often correlate with a higher standard of living. World Bank - Income Level\n\nSocial and Demographic Factors:\n\nMortality Rate: While not a direct predictor of migration, it can influence the desirability of a location indirectly through its impact on life expectancy and the quality of healthcare services. World Bank - Mortality Rate\n\nPopulation Density: Provides insight into how densely populated a region is, which can impact migrants’ decisions. World Bank - Population Density\nPolitical Instability: An indicator of the stability of governance in a region, which can significantly affect migration patterns. World Bank - Worldwide Governance Indicators\n\n\nNetMigration ~ EmploymentRate + IncomeLevels + MortalityRate Net Migration = pol_instab + pop_density + under_5_mortality_rate + total_unemployment + govt_expenditure_education + gni_income\nModel Equation\n\n\nNetMigration = \\(\\beta_0\\) + \\(\\beta_1\\) x Political Instability + \\(\\beta_2\\) x Mortiality rate (under 5) + \\(\\beta_3\\)x unemployment + \\(\\beta_4\\) x Government expenditure onEducation + \\(\\beta_5\\) x GNI Income* x e\n\n\n\\(\\beta_0\\) as intercept, \\(\\beta_1\\) , \\(\\beta_2\\) , \\(\\beta_3\\) , \\(\\beta_4\\) , and \\(\\beta_5\\) as coefficients\nThe model will try to understand what affects net migration (the difference between the number of people entering and leaving a country) by looking at several factors: political instability, mortality rate for children under 5 years old, unemployment rate, government spending on education, and Gross National Income (GNI) per capital."
  },
  {
    "objectID": "posts/post-with-code/index.html#load-necessary-libraries",
    "href": "posts/post-with-code/index.html#load-necessary-libraries",
    "title": "Attempting drivers of migration",
    "section": "",
    "text": "This is a note for the assessment for the position of a data analyist. The model shows the drivers of international migration at Macro, Meso and Micro. The argument is that migration is likely to increase if current drivers persist. This assessment will focus on the macro level variables for easy data access. Micro and Meso level are however recommended to take country nuances into consideration. The following variables will be considered in this assessment.\nData were gathered from the following links and sources, incorporating specific variables relevant to the study:\n\nNet Migration: The difference between the number of people entering and leaving a geographic area over a specific period, serving as a proxy for population movement. World Bank - Net Migration\nIndependent Variables:\n\nEconomic Factors:\n\nEmployment Rate: Reflects the availability of jobs and the health of the economic environment. Regions with higher employment rates attract people due to better job opportunities, acting as a push or pull factor for migrants. This variable is closely linked to Unemployment rates, where lower unemployment rates indicate higher employment opportunities. World Bank - Unemployment\nIncome Levels: The average income or economic prosperity in a region, influencing migration as higher income levels often correlate with a higher standard of living. World Bank - Income Level\n\nSocial and Demographic Factors:\n\nMortality Rate: While not a direct predictor of migration, it can influence the desirability of a location indirectly through its impact on life expectancy and the quality of healthcare services. World Bank - Mortality Rate\n\nPopulation Density: Provides insight into how densely populated a region is, which can impact migrants’ decisions. World Bank - Population Density\nPolitical Instability: An indicator of the stability of governance in a region, which can significantly affect migration patterns. World Bank - Worldwide Governance Indicators\n\n\nNetMigration ~ EmploymentRate + IncomeLevels + MortalityRate Net Migration = pol_instab + pop_density + under_5_mortality_rate + total_unemployment + govt_expenditure_education + gni_income\nModel Equation\n\n\nNetMigration = \\(\\beta_0\\) + \\(\\beta_1\\) x Political Instability + \\(\\beta_2\\) x Mortiality rate (under 5) + \\(\\beta_3\\)x unemployment + \\(\\beta_4\\) x Government expenditure onEducation + \\(\\beta_5\\) x GNI Income* x e\n\n\n\\(\\beta_0\\) as intercept, \\(\\beta_1\\) , \\(\\beta_2\\) , \\(\\beta_3\\) , \\(\\beta_4\\) , and \\(\\beta_5\\) as coefficients\nThe model will try to understand what affects net migration (the difference between the number of people entering and leaving a country) by looking at several factors: political instability, mortality rate for children under 5 years old, unemployment rate, government spending on education, and Gross National Income (GNI) per capital."
  },
  {
    "objectID": "posts/post-with-code/index.html#step-1-data-gathering",
    "href": "posts/post-with-code/index.html#step-1-data-gathering",
    "title": "Attempting drivers of migration",
    "section": "Step 1: Data Gathering",
    "text": "Step 1: Data Gathering\nLoad the variables\n\n# Load first set of dataset  -------------------------\n# Define the base directory\nbase_dir &lt;- \"C:/Users/orenaike/OneDrive/02_JOBS/OT_CV/Jobs_Application/IOM/Interview_Prep/Prep_Grace\"\n\n\n# Define subdirectories\nsub_dirs &lt;- c(\"API_EN.POP.DNST_DS2_en_csv_v2_1512_Pop_Density\",\n              \"API_SH.DYN.MORT_DS2_en_csv_v2_1984_mortality\",\n              \"API_NY.GNP.PCAP.KD_DS2_en_csv_v2_3157_GNI\",\n              \"API_SL.UEM.TOTL.NE.ZS_DS2_en_csv_v2_Unemployment\",\n              \"API_SE.XPD.TOTL.GD.ZS_DS2_en_csv_v2_14_govt_exp\",\n              \"API_SM.POP.NETM_DS2_en_csv_v2_105_Net migration\")\n\n# Initialize an empty list to store data frames\ndf_list &lt;- list()\n\n# Loop through each subdirectory\nfor(dir in sub_dirs) {\n  # Construct the full path to the directory\n  full_dir &lt;- file.path(base_dir, dir)\n  \n  # Find the CSV file that starts with \"API\" in the directory\n  # csv_file &lt;- list.files(full_dir, pattern = \"^API.*//.csv$\", full.names = TRUE)\n  csv_file &lt;- list.files(full_dir, pattern = \"^API.*\\\\.csv$\", full.names = TRUE)\n  \n  # Check if exactly one file is found\n  if(length(csv_file) == 1) {\n    # Read the CSV file from row 5, skip the first 4 rows\n    data &lt;- read.csv(csv_file, skip = 4, stringsAsFactors = FALSE)\n    \n    # Add the data frame to the list\n    df_list[[dir]] &lt;- data\n  } else {\n    cat(\"No file or multiple files found in\", dir, \"/n\")\n  }\n}\n\n# Concatenate all data frames in the list into one\nall_data &lt;- bind_rows(df_list) # The data is currently in wide format. We need to cover to Long for easy analysis \n\n# Check the structure of the concatenated data frame\ndim(all_data) \n\n[1] 1596   68\n\n# load political instability data ----------------\n\npolitical_instab &lt;- read_csv(\"C:/Users/orenaike/OneDrive/02_JOBS/OT_CV/Jobs_Application/IOM/Interview_Prep/Prep_Grace/P_Data_Extract_From_Worldwide_Governance_Indicators/0ac43a1d-ff11-4838-93a9-738e096ed561_Data.csv\")\n\nRows: 219 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Series Name, Series Code, Country Name, Country Code, 2000 [YR2000...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npolitical_instab_v1 &lt;- political_instab |&gt;\n  janitor::clean_names() |&gt;\n  dplyr::filter(series_name == \"Political Stability and Absence of Violence/Terrorism: Estimate\")\n\nhead(political_instab_v1) #check the first few\n\n# A tibble: 6 × 15\n  series_name    series_code country_name country_code x2000_yr2000 x2013_yr2013\n  &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;       \n1 Political Sta… PV.EST      Afghanistan  AFG          -2.43896889… -2.51934909…\n2 Political Sta… PV.EST      Albania      ALB          -0.53998959… 0.091929785…\n3 Political Sta… PV.EST      Algeria      DZA          -1.43257737… -1.20237147…\n4 Political Sta… PV.EST      American Sa… ASM          ..           0.928985774…\n5 Political Sta… PV.EST      Andorra      AND          1.166981458… 1.283926010…\n6 Political Sta… PV.EST      Angola       AGO          -2.03817391… -0.39123347…\n# ℹ 9 more variables: x2014_yr2014 &lt;chr&gt;, x2015_yr2015 &lt;chr&gt;,\n#   x2016_yr2016 &lt;chr&gt;, x2017_yr2017 &lt;chr&gt;, x2018_yr2018 &lt;chr&gt;,\n#   x2019_yr2019 &lt;chr&gt;, x2020_yr2020 &lt;chr&gt;, x2021_yr2021 &lt;chr&gt;,\n#   x2022_yr2022 &lt;chr&gt;"
  },
  {
    "objectID": "posts/New_post/index.html",
    "href": "posts/New_post/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2\n\n\nIn a previous post, we talked about the Oscars and whether prestige awards still matter. Let’s turn now to what is perhaps the mother of all prestige awards — the Nobel Prize. The legacy of Swedish industrialist Alfred Nobel, it honors outstanding achievement in the fields of chemistry, literature, medicine, peace, physics, and, since 1969, economics. Winners — ahem, laureates — receive unparalleled stature not just in their fields but in the public sphere (deservedly or otherwise).\nIn its 120-year history, close to a thousand individuals (and some two dozen organizations) have been given a Nobel. What are they like? As an elite group, you can probably guess that they would tend towards oldness, whiteness, and maleness. But how old, how white, and how male? Fortunately, NobelPrize.org has an API for downloading data on all laureates, through which I was able to compile, for each laureate: the year and category they won in, their sex, their birth date, and their birth country (using modern borders). I won’t be including organizations in my analysis.\nLet’s take a look at the cleaned dataset using reactable, a wonderful table-making package by Greg Lin that I sure wish I discovered earlier. Below is a sortable, searchable, paginated table of the complete dataset:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Orenaike",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 23, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\nSeventy years of surveys tell us that two weeks before an election, about 20% of votes are still up for grabs\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nOrenaike Oluwatosin\n\n\n\n\n\n\n\n\n\n\n\n\nAttempting drivers of migration\n\n\n\n\n\n\nR\n\n\nMachine Learning\n\n\nMigration\n\n\n\n\n\n\n\n\n\nFeb 13, 2024\n\n\nOluwatosin Orenaike\n\n\n\n\n\n\n\n\n\n\n\n\nGeofencing with R for Enhanced Data Collection in Kobotoolbox\n\n\nGeofencing is a powerful tool that combines location technology with data analysis allowing you to automate and check data collection within predefined geographical boundaries.\n\n\n\nR\n\n\nKobotoolbox\n\n\nData Collection\n\n\n\n\n\n\n\n\n\nJan 5, 2024\n\n\nOluwatosin Orenaike\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Finley Malloc is the Chief Data Scientist at Wengo Analytics. When not innovating on data platforms, Finley enjoys spending time unicycling and playing with her pet iguana.\n\n\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011\n\n\n\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018\n\n \n  \n   \n  \n    \n     twitter\n  \n  \n    \n     Github\n  \n\n\n\n Thanks for stopping by! If you have any questions or would like to work together, please don’t hesitate to contact me."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "",
    "text": "University of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About me",
    "section": "",
    "text": "Wengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018"
  },
  {
    "objectID": "portfolio.html#welcome-to-my-page",
    "href": "portfolio.html#welcome-to-my-page",
    "title": "Orenaikeblog",
    "section": "Welcome to my page!",
    "text": "Welcome to my page!\nHere, you will find samples of my work. I specialize in using R, Python, and Adobe Creative Suite, including InDesign, Photoshop, and Illustrator, for data visualization, data wrangling, and data analysis. I also have experience with ArcGIS Pro, ArcGIS Online, and QGIS for geospatial data analysis, as well as Jupyter and R Markdown for data visualization and geospatial analysis. I can use SQL in managing relational database. Additionally, I am currently learning Web Development.\n\nMy core skills include:\n\nStrong computer background with experience in relational databases, Microsoft applications, spreadsheets, word processing, GIS, graphic design, and desktop publishing.\nData management, research, and analysis experience with both quantitative and qualitative data.\nExperience with analytics and visualization tools such as open viz libraries like Shiny and flexdashboard.\nDemonstrated experience developing risk index model at national and global scale\nProficient in using and maintaining spatial and non-spatial technology products.\nStrong information management architecture knowledge, Kobo development, concepts of Relational Database Systems.\nExperience working with local and international organizations, including UN-IOM, UNDP, UNSPIDER and EU.\nExcellent analytical and organizational skills, communication, writing and reporting skills, and multicultural skills.\nExpertise in Earth Observation and GIS Risk Analysis and remote sensing analysis (Floods extraction, buildings damage assessment, population affected monitoring).\nAbility to build strong and sustainable relationships, interact at all levels within the organization, work independently, and lead teams.\nThematic experience includes Migration, Displacement, Humanitarian and Droughts.I am also exploring application of AI to optimize outputs.\n\n\n\n\n Thanks for stopping by! If you have any questions or would like to work together, please don’t hesitate to contact me."
  },
  {
    "objectID": "posts/geofencing/index.html",
    "href": "posts/geofencing/index.html",
    "title": "Geofencing with R for Enhanced Data Collection in Kobotoolbox",
    "section": "",
    "text": "Geofencing is a powerful tool that combines location technology with data analysis, allows you to automate data collection within predefined geographical boundaries. I will show you a step-by-step guide, using R, to integrate geofencing with Kobotoolbox and boost your data collection efficiency. This process involves two major steps:\n\nGetting the vertex for your location of interest.\nUploading vertex to KoboToolbox (link to a video).\n\nImagine this:\n\nYou enter a designated study area, and data collection triggers automatically. No more remembering to press buttons or check locations!\nYour data comes from precisely where you need it, thanks to the power of geofencing boundaries. No more worrying about stray data points or missed locations!\nKobotoolbox forms adapt based on location, with possibilities of dynamically changing questions or displaying relevant information for specific areas.\n\nLet’s dive in!"
  },
  {
    "objectID": "posts/geofencing/index.html#step-1-shape-up-your-boundaries",
    "href": "posts/geofencing/index.html#step-1-shape-up-your-boundaries",
    "title": "Geofencing with R for Enhanced Data Collection in Kobotoolbox",
    "section": "Step 1: Shape Up Your Boundaries",
    "text": "Step 1: Shape Up Your Boundaries\nFirst, define your geofencing areas. Grab the shapefiles for your target zones — these handy files store information about geographical boundaries. Our example uses a sample shapefile named “Sample_locations” with details like Sites, Zones, House, and Blocks. Download it here: [link to your sample shapefile]\n\n# Load your shapefile (ensure you provide the correct path)\nSample_locations &lt;- st_read(\"./data/shp_file/Sample_locations.shp\")\n\nReading layer `Sample_locations' from data source \n  `C:\\Users\\orenaike\\OneDrive\\01_ORENAIKE\\02_CAREER_AND_DEVELOPMENTS\\01_Schools\\Web_Development\\Portfolio\\otomisin.github.io\\posts\\geofencing\\data\\shp_file\\Sample_locations.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 605820.6 ymin: 853074.4 xmax: 606177 ymax: 853555.9\nProjected CRS: WGS 84 / UTM zone 35N\n\n# Check and plot the data table to understand its structure\nprint(st_drop_geometry(Sample_locations))\n\n  OBJECTID Zone_ Block   House\n1        1     B     1 House A\n2        2     B     2 House B\n3        3     A     1 House C\n4        4     A     2 House D\n5        5     A     3 House E\n6        6     A     4 House F\n\n# Plot the locations\nSample_locations |&gt;\n  ggplot() +\n  geom_sf() +\n  geom_label(aes(x = st_coordinates(st_centroid(geometry))[, 1], \n                 y = st_coordinates(st_centroid(geometry))[, 2], \n                 label = House), \n             size = 3, fill = \"lightblue\", color = \"black\") +\n  theme_void()\n\n\n\n\n\n\n\n\n."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/geofencing/index.html#step-2-extract-those-coordinates",
    "href": "posts/geofencing/index.html#step-2-extract-those-coordinates",
    "title": "Geofencing with R for Enhanced Data Collection in Kobotoolbox",
    "section": "Step 2: Extract Those Coordinates",
    "text": "Step 2: Extract Those Coordinates\nNow, use R’s st_geometry function to extract the precise latitude and longitude values from your shapefile. We’ll store these coordinates in a separate data frame for easier manipulation.\n\n# Extract coordinates using the same Coordinate Reference System (CRS) as the original data\npolygon_vertices &lt;- lapply(st_geometry(Sample_locations), st_coordinates)\n\n# Map each polygon_vertices list to its OBJECTID row\nmapped_data_v1 &lt;- Map(function(vertices, objectid) {\n  data.frame(OBJECTID = objectid,\n             p_longitude = vertices[, \"X\"],\n             p_latitude = vertices[, \"Y\"])\n}, polygon_vertices, Sample_locations$OBJECTID)\n\n# Combine the mapped data frames into a single data frame\nmapped_data_v1 &lt;- do.call(rbind, mapped_data_v1)\n\n# Integrate the mapped data with the original shapefile data\nSample_locations_points &lt;- Sample_locations |&gt;\n  as.data.frame() |&gt;\n  left_join(mapped_data_v1, by = \"OBJECTID\") |&gt;\n  st_as_sf(coords = c(\"p_longitude\", \"p_latitude\"), crs = st_crs(Sample_locations))\n\n\nsummary(Sample_locations_points)\n\n    OBJECTID        Zone_              Block              House          \n Min.   :1.000   Length:66          Length:66          Length:66         \n 1st Qu.:1.000   Class :character   Class :character   Class :character  \n Median :2.000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2.667                                                           \n 3rd Qu.:4.000                                                           \n Max.   :6.000                                                           \n          geometry \n POINT        :66  \n epsg:32635   : 0  \n +proj=utm ...: 0"
  },
  {
    "objectID": "posts/geofencing/index.html#step-3-generate-your-id-nodes",
    "href": "posts/geofencing/index.html#step-3-generate-your-id-nodes",
    "title": "Geofencing with R for Enhanced Data Collection in Kobotoolbox",
    "section": "Step 3: Generate Your ID Nodes",
    "text": "Step 3: Generate Your ID Nodes\n\nSample_locations_points_v1 &lt;- Sample_locations_points %&gt;%\n  group_by(Block) %&gt;%\n  mutate(id_node = paste0(Block, \"_\", row_number())) %&gt;%\n  ungroup()\n\n# View the points and polygons on a map\nggplot() +\n  geom_sf(data = Sample_locations) +\n  geom_label(data = Sample_locations_points_v1,\n             aes(x = st_coordinates(st_centroid(geometry))[, 1],\n                 y = st_coordinates(st_centroid(geometry))[, 2],\n                 label = House),\n             size = 3, fill = \"lightblue\", color = \"black\") +\n  geom_sf(data = Sample_locations_points_v1) +\n  theme_void()"
  },
  {
    "objectID": "posts/geofencing/index.html#step-5-export-the-spatial-data-for-kobotoolbox-integration",
    "href": "posts/geofencing/index.html#step-5-export-the-spatial-data-for-kobotoolbox-integration",
    "title": "Geofencing with R for Enhanced Data Collection in Kobotoolbox",
    "section": "Step 5: Export the Spatial Data for Kobotoolbox Integration",
    "text": "Step 5: Export the Spatial Data for Kobotoolbox Integration\n\nwrite.csv(Sample_locations_points_v1, \"./Sample_locations_points_v1.csv\")\n\n# The exported CSV file can now be used in Kobotoolbox for enhanced data collection with geofencing\n\nStep 5: Integrate with Kobotoolbox\nCongratulations! You now have a spatial data frame enriched with precise coordinates and unique identifiers, ready to be seamlessly integrated with Kobotoolbox. Unleash the power of location-aware data collection, with automatic form triggers and data collection tailored to specific geographical zones.\nBeyond the Code: Here are some additional tips to take your geofencing journey to the next level:\n\nReal-world examples: Think about using geofencing to study air quality in specific city districts, automatically triggering data collection at designated times.\nChallenges and solutions: Consider potential challenges like battery drain on data collectors and GPS limitations. Optimize data collection forms and schedule strategically to mitigate these.\nDive deeper: Explore our GitHub repository (link here) for the full code buffet and detailed tutorials to become a geofencing master.\n\nDon’t let your data collection be stuck in the manual age! Leverage the magic of geofencing with R and Kobotoolbox to supercharge your fieldwork efficiency and precision and experience the power of automation, precision, and streamlined workflows!\nYou can check how to integrate the output into Kobotoolbox. Check this video on how to."
  }
]